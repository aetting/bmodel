Training set: trainingpairs-br-origfulldutch
Embeddings: brouwerCOALS-100.txt
Binary: True
Context 200, Retrieval 80
Vocab 35, Embedding 100

TRAINING PART ONE

100 items per update, 7000 total updates

NetInteg (
  (integ): Linear (300 -> 200)
  (integ_out): Linear (200 -> 300)
)

loss: 198.416320741  lr: 0.2
loss: 109.998372335  lr: 0.2
loss: 98.7357657207  lr: 0.2
loss: 84.6448159171  lr: 0.2
loss: 94.7242273141  lr: 0.2
loss: 78.673645142  lr: 0.2
loss: 80.7558894317  lr: 0.2
loss: 77.2323942349  lr: 0.2
loss: 76.6186073223  lr: 0.2
loss: 71.0581856006  lr: 0.2
loss: 62.7019794838  lr: 0.2
loss: 67.1885221353  lr: 0.2
loss: 69.4073370395  lr: 0.2
loss: 67.5867285938  lr: 0.2
loss: 69.5624328605  lr: 0.2
loss: 62.9577316776  lr: 0.2
loss: 65.4550947304  lr: 0.2
loss: 68.0351497408  lr: 0.2
loss: 64.1739623531  lr: 0.2
loss: 62.8728236021  lr: 0.2
loss: 62.3521106451  lr: 0.2
loss: 64.5613435404  lr: 0.2
loss: 64.1567658434  lr: 0.2
loss: 66.5281858683  lr: 0.2
loss: 60.8788264272  lr: 0.2
loss: 64.8804379546  lr: 0.2
loss: 64.3996234277  lr: 0.2
loss: 61.9397137745  lr: 0.2
loss: 56.5129633559  lr: 0.2
loss: 64.0626542406  lr: 0.2
loss: 65.3260993206  lr: 0.2
loss: 64.5275563343  lr: 0.2
loss: 57.2639673235  lr: 0.2
loss: 58.9932707215  lr: 0.2
loss: 61.4447180574  lr: 0.2
loss: 55.5414726183  lr: 0.2
loss: 58.4776987324  lr: 0.2
loss: 61.3739943789  lr: 0.2
loss: 63.722588948  lr: 0.2
loss: 58.0071139611  lr: 0.2
loss: 59.6975122279  lr: 0.2
loss: 65.4954953178  lr: 0.2
loss: 61.2811357188  lr: 0.2
loss: 57.2794816714  lr: 0.2
loss: 60.959127098  lr: 0.2
loss: 70.6964537691  lr: 0.2
loss: 56.8416169045  lr: 0.2
loss: 58.424955727  lr: 0.2
loss: 62.9832529092  lr: 0.2
loss: 64.8477425883  lr: 0.2
loss: 65.2745080961  lr: 0.2
loss: 61.7415832956  lr: 0.2
loss: 63.5477973468  lr: 0.2
loss: 60.1277326803  lr: 0.2
loss: 60.161747381  lr: 0.2
loss: 56.7413237068  lr: 0.2
loss: 66.5570878356  lr: 0.2
loss: 56.2442279608  lr: 0.2
loss: 60.2677545313  lr: 0.2
loss: 57.7329292132  lr: 0.2
loss: 57.9546578761  lr: 0.2
loss: 63.0269669441  lr: 0.2
loss: 53.4425827826  lr: 0.2
loss: 58.0374106643  lr: 0.2
loss: 57.1033670236  lr: 0.2
loss: 63.2743492694  lr: 0.2
loss: 58.0471976792  lr: 0.2
loss: 59.3670625301  lr: 0.2
loss: 61.4073778913  lr: 0.2
loss: 61.2474232298  lr: 0.2

Correct: 16000 out of 16000 (1.0)

TRAINING PART TWO

100 items per update, 7000 total updates

NetFull (
  (retr): Linear (235 -> 80)
  (retr_out): Linear (80 -> 100)
  (integ): Linear (300 -> 200)
  (integ_out): Linear (200 -> 300)
)

loss: 178.977497146  lr: 0.2
loss: 152.830792889  lr: 0.2
loss: 135.035990778  lr: 0.2
loss: 111.296403291  lr: 0.2
loss: 103.527698681  lr: 0.2
loss: 84.3324733897  lr: 0.2
loss: 67.8436777626  lr: 0.2
loss: 67.9884942989  lr: 0.2
loss: 56.5320483969  lr: 0.2
loss: 65.5070031803  lr: 0.2
loss: 61.8638314223  lr: 0.2
loss: 63.9170385171  lr: 0.2
loss: 68.7801734002  lr: 0.2
loss: 62.9701899613  lr: 0.2
loss: 63.482756187  lr: 0.2
loss: 60.7410126468  lr: 0.2
loss: 61.5592555926  lr: 0.2
loss: 52.9970027986  lr: 0.2
loss: 58.4105246941  lr: 0.2
loss: 59.801149075  lr: 0.2
loss: 60.141801277  lr: 0.2
loss: 61.2178577785  lr: 0.2
loss: 64.5176096487  lr: 0.2
loss: 58.5492490134  lr: 0.2
loss: 52.2469033854  lr: 0.2
loss: 63.8862945015  lr: 0.2
loss: 64.8224082548  lr: 0.2
loss: 63.8403740362  lr: 0.2
loss: 56.8612112793  lr: 0.2
loss: 62.7765603269  lr: 0.2
loss: 62.0083232058  lr: 0.2
loss: 61.5789114082  lr: 0.2
loss: 59.3796799844  lr: 0.2
loss: 57.0326768781  lr: 0.2
loss: 63.6821029601  lr: 0.2
loss: 61.8695403794  lr: 0.2
loss: 60.1658878052  lr: 0.2
loss: 61.6015159256  lr: 0.2
loss: 57.929905233  lr: 0.2
loss: 64.7123346231  lr: 0.2
loss: 59.7643906018  lr: 0.2
loss: 57.7166148619  lr: 0.2
loss: 63.2351752734  lr: 0.2
loss: 66.2603317226  lr: 0.2
loss: 61.2155244952  lr: 0.2
loss: 60.0610316567  lr: 0.2
loss: 59.4409785589  lr: 0.2
loss: 59.0590155901  lr: 0.2
loss: 59.0122343585  lr: 0.2
loss: 64.9788005636  lr: 0.2
loss: 55.9644599448  lr: 0.2
loss: 63.1111033393  lr: 0.2
loss: 68.0683740743  lr: 0.2
loss: 58.4219917938  lr: 0.2
loss: 59.294588815  lr: 0.2
loss: 61.6061259587  lr: 0.2
loss: 58.5532707492  lr: 0.2
loss: 59.9018957182  lr: 0.2
loss: 60.1332339328  lr: 0.2
loss: 56.6789223935  lr: 0.2
loss: 55.2871935302  lr: 0.2
loss: 58.399425202  lr: 0.2
loss: 69.6645995709  lr: 0.2
loss: 64.2923582318  lr: 0.2
loss: 67.0863583367  lr: 0.2
loss: 58.5048514492  lr: 0.2
loss: 60.2564210577  lr: 0.2
loss: 64.6719958759  lr: 0.2
loss: 60.7019103948  lr: 0.2
loss: 60.9847756878  lr: 0.2

Correct: 16000 out of 16000 (1.0)

