Training set: trainingpairs-br-origfulldutch
Training code: p2
Embeddings: embs/brouwerCOALS-100.txt
Binary: True
Reduce lr: False
Context 200, Retrieval 80
Vocab 35, Embedding 100

Notes: full model only training with NONstereotypical only


TRAINING PART TWO

100 items per update, 7000 total updates

NetFull (
  (retr): Linear (235 -> 80)
  (retr_out): Linear (80 -> 100)
  (integ): Linear (300 -> 200)
  (integ_out): Linear (200 -> 300)
)

loss: 138.65231958  lr: 0.2
loss: 141.131156072  lr: 0.2
loss: 141.62006104  lr: 0.2
loss: 136.897354901  lr: 0.2
loss: 137.681439519  lr: 0.2
loss: 125.549751416  lr: 0.2
loss: 128.641969964  lr: 0.2
loss: 114.300205067  lr: 0.2
loss: 115.927211011  lr: 0.2
loss: 114.029868718  lr: 0.2
loss: 109.273571851  lr: 0.2
loss: 113.867434738  lr: 0.2
loss: 106.347853549  lr: 0.2
loss: 106.637257468  lr: 0.2
loss: 115.036357046  lr: 0.2
loss: 103.874998114  lr: 0.2
loss: 97.6124043111  lr: 0.2
loss: 80.9240966727  lr: 0.2
loss: 104.112921014  lr: 0.2
loss: 94.7939210703  lr: 0.2
loss: 96.8764277832  lr: 0.2
loss: 93.6495656692  lr: 0.2
loss: 98.1840310127  lr: 0.2
loss: 88.3362698753  lr: 0.2
loss: 80.9121191679  lr: 0.2
loss: 99.9644115001  lr: 0.2
loss: 79.2298700421  lr: 0.2
loss: 93.0170798728  lr: 0.2
loss: 76.8533148749  lr: 0.2
loss: 77.5033333407  lr: 0.2
loss: 90.1612847951  lr: 0.2
loss: 77.4045121226  lr: 0.2
loss: 78.6533384456  lr: 0.2
loss: 80.6135224374  lr: 0.2
loss: 64.9293952064  lr: 0.2
loss: 71.1234001759  lr: 0.2
loss: 80.1649768367  lr: 0.2
loss: 62.3101137887  lr: 0.2
loss: 76.3523331145  lr: 0.2
loss: 64.9618866568  lr: 0.2
loss: 70.3002727014  lr: 0.2
loss: 67.839257831  lr: 0.2
loss: 56.1027597665  lr: 0.2
loss: 61.8096610304  lr: 0.2
loss: 63.9367382789  lr: 0.2
loss: 62.578652785  lr: 0.2
loss: 67.5941494923  lr: 0.2
loss: 67.0133151164  lr: 0.2
loss: 59.22723147  lr: 0.2
loss: 66.827385132  lr: 0.2
loss: 64.234169812  lr: 0.2
loss: 62.4146612639  lr: 0.2
loss: 63.9088719748  lr: 0.2
loss: 61.1435965954  lr: 0.2
loss: 58.1088493339  lr: 0.2
loss: 64.8170775256  lr: 0.2
loss: 62.0740910916  lr: 0.2
loss: 59.0692214793  lr: 0.2
loss: 66.7239775048  lr: 0.2
loss: 63.4633813284  lr: 0.2
loss: 62.7899700552  lr: 0.2
loss: 60.1827376302  lr: 0.2
loss: 56.3123390109  lr: 0.2
loss: 55.824029247  lr: 0.2
loss: 58.1310396893  lr: 0.2
loss: 60.9252293627  lr: 0.2
loss: 54.5664764792  lr: 0.2
loss: 60.4314121851  lr: 0.2
loss: 58.3039627507  lr: 0.2
loss: 55.6381121543  lr: 0.2
lastloss: 55.6381121543 lr: 0.2 update: 7000

Correct: 16000 out of 16000 (1.0)

