Training set: trainingpairs-br-origfulldutch
Embeddings: brouwerCOALS-100.txt
Binary: True
Context 200, Retrieval 80
Vocab 35, Embedding 100

TRAINING PART ONE

2 items per update, 7000 total updates

NetInteg (
  (integ): Linear (300 -> 200)
  (integ_out): Linear (200 -> 300)
)

loss: 2.64296084642  lr: 0.2
loss: 2.69846431911  lr: 0.2
loss: 2.74536585808  lr: 0.2
loss: 2.46446736157  lr: 0.2
loss: 2.84862212837  lr: 0.2
loss: 2.6689209491  lr: 0.2
loss: 2.30571690947  lr: 0.2
loss: 2.68451716751  lr: 0.19
loss: 1.87374078482  lr: 0.19
loss: 1.91571260989  lr: 0.19
loss: 1.98032767326  lr: 0.19
loss: 1.58145916462  lr: 0.19
loss: 2.14913301542  lr: 0.19
loss: 1.95025691949  lr: 0.19
loss: 0.755876239389  lr: 0.1805
loss: 2.68456548452  lr: 0.1805
loss: 1.82741097268  lr: 0.1805
loss: 0.832936302759  lr: 0.1805
loss: 1.79808893614  lr: 0.1805
loss: 1.78169722389  lr: 0.1805
loss: 0.701328487135  lr: 0.1805
loss: 1.91367084906  lr: 0.171475
loss: 1.84535293281  lr: 0.171475
loss: 2.04268233199  lr: 0.171475
loss: 1.69387667999  lr: 0.171475
loss: 2.53450416028  lr: 0.171475
loss: 2.62685767189  lr: 0.171475
loss: 0.965250094421  lr: 0.171475
loss: 2.71793481708  lr: 0.16290125
loss: 1.70803369675  lr: 0.16290125
loss: 0.689120350406  lr: 0.16290125
loss: 2.07922396995  lr: 0.16290125
loss: 0.844850980677  lr: 0.16290125
loss: 2.39091712236  lr: 0.16290125
loss: 1.00451363157  lr: 0.16290125
loss: 1.96468108241  lr: 0.1547561875
loss: 2.11900007538  lr: 0.1547561875
loss: 3.5482545048  lr: 0.1547561875
loss: 0.808638318442  lr: 0.1547561875
loss: 1.38937717211  lr: 0.1547561875
loss: 0.815982395783  lr: 0.1547561875
loss: 2.18968593003  lr: 0.1547561875
loss: 2.07777931541  lr: 0.147018378125
loss: 2.87352073193  lr: 0.147018378125
loss: 2.85232333839  lr: 0.147018378125
loss: 3.08237671852  lr: 0.147018378125
loss: 2.64000603557  lr: 0.147018378125
loss: 1.57430862263  lr: 0.147018378125
loss: 0.599565773737  lr: 0.147018378125
loss: 1.38689902844  lr: 0.139667459219
loss: 1.53248116886  lr: 0.139667459219
loss: 1.75858622789  lr: 0.139667459219
loss: 1.92921090825  lr: 0.139667459219
loss: 0.965866998769  lr: 0.139667459219
loss: 2.77783688903  lr: 0.139667459219
loss: 3.15945772827  lr: 0.139667459219
loss: 3.2955635488  lr: 0.132684086258
loss: 1.82831567107  lr: 0.132684086258
loss: 2.0668569929  lr: 0.132684086258
loss: 1.36742281541  lr: 0.132684086258
loss: 1.8455555574  lr: 0.132684086258
loss: 2.07222937234  lr: 0.132684086258
loss: 3.13876971602  lr: 0.132684086258
loss: 2.71264189482  lr: 0.126049881945
loss: 1.76169176772  lr: 0.126049881945
loss: 1.90717544872  lr: 0.126049881945
loss: 2.43078130484  lr: 0.126049881945
loss: 0.75117131928  lr: 0.126049881945
loss: 1.65447654156  lr: 0.126049881945
loss: 1.57867921516  lr: 0.126049881945

Correct: 0.0 out of 1.0 (0.0)

TRAINING PART TWO

2 items per update, 7000 total updates

NetFull (
  (retr): Linear (235 -> 80)
  (retr_out): Linear (80 -> 100)
  (integ): Linear (300 -> 200)
  (integ_out): Linear (200 -> 300)
)

loss: 2.53916062415  lr: 0.2
loss: 2.50139965117  lr: 0.2
loss: 3.1929988116  lr: 0.2
loss: 2.42192934453  lr: 0.2
loss: 2.80793383718  lr: 0.2
loss: 2.80144716799  lr: 0.2
loss: 3.04022721946  lr: 0.2
loss: 2.93294081092  lr: 0.19
loss: 3.04494582117  lr: 0.19
loss: 2.848288849  lr: 0.19
loss: 2.61600787938  lr: 0.19
loss: 2.43338236213  lr: 0.19
loss: 3.23767836392  lr: 0.19
loss: 2.77863484621  lr: 0.19